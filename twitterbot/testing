import re
import tweepy
from tweepy import OAuthHandler
from textblob import TextBlob
import pandas as pd

 
from keys import *

#region
print('')
print('')
print('starting up...', flush=True)
#time.sleep(2)
print('starting up...', flush=True)
#time.sleep(2)
print('')
print('bringing twitterbot "Robot Overlord 2287" online...', flush=True)
#time.sleep(0.8)
print('twitterbot "Robot Overlord 2287" now online', flush=True)
#time.sleep(1)
print('')
print('beginning search through @robot_2287 mentions...', flush=True)
#time.sleep(2)
print('')
#endregion

from keys import *




class TwitterClient(object):
    '''
    Generic Twitter Class for sentiment analysis.
    '''
    def __init__(self):
        '''
        Class constructor or initialization method.
        '''
        # attempt authentication
        try:
            auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)
            auth.set_access_token(ACCESS_KEY, ACCESS_SECRET)
            self.api = tweepy.API(auth)

            self.client = tweepy.Client(consumer_key=CONSUMER_KEY,consumer_secret=CONSUMER_SECRET,access_token=ACCESS_KEY,access_token_secret=ACCESS_SECRET)
            '''
            # create OAuthHandler object
            self.auth = OAuthHandler(consumer_key, consumer_secret)
            # set access token and secret
            self.auth.set_access_token(access_token, access_token_secret)
            # create tweepy API object to fetch tweets
            self.api = tweepy.API(self.auth)
            '''
        except:
            print("Error: Authentication Failed")
 
    def clean_tweet(self, tweet):
        '''
        Utility function to clean tweet text by removing links, special characters
        using simple regex statements.
        '''
        return ' '.join(re.sub("(@[A-Za-z0-9]+)|([^0-9A-Za-z \t])|(\w+:\/\/\S+)", " ", tweet).split())
 
    def get_tweet_sentiment(self, tweet):
        '''
        Utility function to classify sentiment of passed tweet
        using textblob's sentiment method
        '''
        # create TextBlob object of passed tweet text
        analysis = TextBlob(self.clean_tweet(tweet))
        # set sentiment
        if analysis.sentiment.polarity > 0:
            return 'positive'
        elif analysis.sentiment.polarity == 0:
            return 'neutral'
        else:
            return 'negative'
 
    def preprocess_tweet(tweetlist):
        """this is a function that takes a dataframe with a list of tweets and cleans it up to return only the relevant text.

        Args:
            tweetlist (_type_): _description_
        """
        tweets=tweetlist['text'].values
 
        # Converting the text column as a single string for wordcloud
        tweet_text=str(tweets)
  
        # Converting the whole text to lowercase
        tweet_text = tweet_text.lower()
 
        # Removing the twitter usernames from tweet string
        tweet_text=re.sub(r'@\w+', ' ', tweet_text)
 
        # Removing the URLS from the tweet string
        tweet_text=re.sub(r'http\S+', ' ', tweet_text)
 
 
        # Deleting everything which is not characters
        tweet_text = re.sub(r'[^a-z A-Z]', ' ',tweet_text)
 
        # Deleting any word which is less than 3-characters mostly those are stopwords
        tweet_text = re.sub(r'\b\w{1,2}\b', '', tweet_text)
 
        # Stripping extra spaces in the text
        tweet_text= re.sub(r' +', ' ', tweet_text)
 
        return tweet_text
    
    def get_tweets(self, query, count = 10):
        '''
        Main function to fetch tweets and parse them.
        '''
        # empty list to store parsed tweets
        tweets = []
 
        try:
            # call twitter api to fetch tweets
            fetched_tweets = self.api.search_tweets(q = query, count = count)
 
            # parsing tweets one by one
            for tweet in fetched_tweets:
                # empty dictionary to store required params of a tweet
                parsed_tweet = {}
 
                # saving text of tweet
                parsed_tweet['text'] = tweet.text
                # saving sentiment of tweet
                parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text)
 
                # appending parsed tweet to tweets list
                if tweet.retweet_count > 0:
                    # if tweet has retweets, ensure that it is appended only once
                    if parsed_tweet not in tweets:
                        tweets.append(parsed_tweet)
                else:
                    tweets.append(parsed_tweet)
 
            # return parsed tweets
            tweet_list_df = pd.DataFrame(tweets)
            #tweet_list_df = pd.DataFrame(tweet_list_df['text'])

            print(tweet_list_df.head(5))
            print('')
            return tweets
 
        except tweepy.TweepError as e:
            # print error (if any)
            print("Error : " + str(e))
 
def main():
    # creating object of TwitterClient Class
    api = TwitterClient()
    # calling function to get tweets
    tweets = api.get_tweets(query = 'great british bake off', count = 200)
 
    # picking positive tweets from tweets
    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive']
    # percentage of positive tweets
    print("Positive tweets percentage: {} %".format(100*len(ptweets)/len(tweets)))
    # picking negative tweets from tweets
    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative']
    # percentage of negative tweets
    print("Negative tweets percentage: {} %".format(100*len(ntweets)/len(tweets)))
    # percentage of neutral tweets
    print("Neutral tweets percentage: {} % \
        ".format(100*(len(tweets) -(len( ntweets )+len( ptweets)))/len(tweets)))
 
    # printing first 5 positive tweets
    print("\n\nPositive tweets:")
    for tweet in ptweets[:10]:
        print(tweet['text'])
        print("-------------------")
 
    # printing first 5 negative tweets
    print("\n\nNegative tweets:")
    for tweet in ntweets[:10]:
        print(tweet['text'])
 
if __name__ == "__main__":
    # calling main function
    main()
